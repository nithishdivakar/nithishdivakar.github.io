<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><title>Gradient Through Concatenation | DAXPY</title><link rel=stylesheet href=/css/main.min.94a2540136d9a839e3ae21136b6ed35c457b231d8bd1a157c7089710a8682c84.css integrity="sha256-lKJUATbZqDnjriETa27TXEV7Ix2L0aFXxwiXEKhoLIQ=" crossorigin=anonymous><script src=/js/main.23cd0c7d837263b9eaeb96ee2d9ccfa2969daa3fa00fa1c1fe8701a9b87251a1.js integrity="sha256-I80MfYNyY7nq65buLZzPopadqj+gD6HB/ocBqbhyUaE=" crossorigin=anonymous></script></head><body><header><nav><ul><li><a class=text_secondary href=https://daxpy.xyz/>DAXPY</a></li><li>|</li><li><a href=https://daxpy.xyz/posts/>Posts</a></li><li><a href=https://daxpy.xyz/notes/>Notes</a></li><li><a href=https://daxpy.xyz/collections/>Collections</a></li><li><a href=https://daxpy.xyz/links/>Links</a></li><li><a href=https://daxpy.xyz/stories/>Stories</a></li><li><a href=/about>About</a></li></ul></nav></header><main><section><article><h1 id=gradient-through-concatenation>Gradient Through Concatenation</h1><p>Concatenation of vectors is a common operation in Deep Learning Networks. How can we compute derivative of the
output in the computational graph?</p><p>We can write the operation as</p><p>$$z = x|y$$</p><p>Where $|$ is concat operator. We are interested in computing ${\partial z}/{\partial x}$ and ${\partial z}/{\partial y}$</p><p>Assuming $x\in \mathbb{R}^m$ and $x\in \mathbb{R}^n$. We can rewrite the concat operation as</p><p>$$z = \begin{bmatrix}I_m & 0\end{bmatrix}x+\begin{bmatrix}0 & I_n\end{bmatrix}y$$</p><p>with $I_k$ as identity matrix of size $k \times k$. Then we have</p><p>$$\begin{aligned}
\frac{\partial z}{\partial x} &= \begin{bmatrix}I_m & 0\end{bmatrix}
&
\frac{\partial z}{\partial y} &= \begin{bmatrix}0 & I_n\end{bmatrix}
\end{aligned}$$</p></article><br><br><br><i>tags:</i>
<a class=gray style=padding-right:5px href=/tags#computational-graph><i>#computational-graph</i></a></section></main><footer><p>Found something useful here? pass it on; or tell me about it!<nav><ul><li><a href="https://drive.google.com/drive/folders/18LU6PKnxy8rDrAXhpiPXV2yOYlO_I8cF?usp=sharing">Resume</a></li><li><a href=https://daxpy.xyz/collections/>Collections</a></li><li><a href=https://www.linkedin.com/in/ndivakar/>Linkedin</a></li></ul></nav><small><a href=#top>â†‘ Top of page</a></small></p></footer></body></html>