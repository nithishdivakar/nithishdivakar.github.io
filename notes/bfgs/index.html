<!doctype html><html style=height:100%><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://daxpy.xyz/favicon.ico><link rel=stylesheet href=/css/style.min.css><link href="//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic" rel=stylesheet type=text/css><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><title>BFGS</title></head><body style=height:100%><div class=header><header id=banner style=display:flex;flex-direction:row;flex-wrap:nowrap;justify-content:flex-start;align-items:baseline><big class=h2 style="flex:0 0 80px"><b><a href=https://daxpy.xyz/ class=black>daxpy</a></b></big><nav style=flex:0px><ul style="display:flex;flex-direction:row;gap:1rem;justify-content:safe flex-end"><li><a href=https://daxpy.xyz/notes/>Notes</a></li><li><a href=https://daxpy.xyz/posts/>Posts</a></li><li><a href=https://daxpy.xyz/links/>Links</a></li><li><a href=https://daxpy.xyz/links_fav/>Links</a></li><li><a href=https://daxpy.xyz/stories/>Stories</a></li><li><a href=/about>about</a></li></ul></nav></header><hr style=margin:0></div><div class="container justify" style=display:flex;flex-direction:column;min-height:100vh><div class=main style=flex:1><main id=content><section><article><h1 id=bfgs>BFGS</h1><h2 id=newtons-method>Newton&rsquo;s Method</h2><p>$$\begin{aligned}
x_{k+1} &= x_k - [H(x_k)]^{-1}\nabla f(x_k)^\intercal
\end{aligned}$$</p><h2 id=quasi-newtons-method>Quasi Newton&rsquo;s Method</h2><p>$$\begin{aligned}
x_{k+1} &= x_k - \alpha_kS_k {\nabla f(x_k)}^{T}
\end{aligned}$$</p><p>If $S_k$ is inverse of Hessian, then method is Newton&rsquo;s iteration; if $S_k=I$, then it is steepest descent</p><h2 id=bfgs-1>BFGS</h2><p>BFGS is a quasi newtons method where we approximate inverse of Hessian by $B_k$. The search direction $p_k$ is determined by solving
$$B_kp_k = -\nabla f(x_k)$$
A line search is performed in this search direction to find next point $x_{k+1}$ by minimising $f(x_k+\gamma p_k)$. The approximation to hessian is then updated as
$$\begin{aligned}
B_{k+1} &= B_k + \alpha_k u_ku_k^\intercal + \beta_k v_kv_k^\intercal
\\
u_k &= \nabla f(x_{k+1})-\nabla f(x_k)
\\
\alpha_k &= \frac{1}{\alpha u_k^\intercal p_k}
\\
v_k &= B_kp_k
\\
\beta_k &= \frac{-1}{p_k^\intercal B_kp_k}
\end{aligned}$$</p></article><br><br><br><i>tags:</i>
<a class=gray style=padding-right:5px href=/tags#optimisation><i>#optimisation</i></a></section></main></div><div class=footer><br><br><hr style=margin:0><footer id=footer style=display:flex;justify-content:space-between><div>Ping me <a target=_blank class=green href=https://twitter.com/nithishdivakar>@nithishdivakar</a></div><div><a href=/resources target=_blank>::</a></div></footer></div></div></body></html>