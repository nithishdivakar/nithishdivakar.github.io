<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><title>RankNet and LambdaRank | DAXPY</title><link rel=stylesheet href=/css/main.min.9e0d91ee5e43768adbd3e495fb3273f760195e4e09cae07eb8461013ded5303d.css integrity="sha256-ng2R7l5Ddorb0+SV+zJz92AZXk4JyuB+uEYQE97VMD0=" crossorigin=anonymous><script src=/js/main.23cd0c7d837263b9eaeb96ee2d9ccfa2969daa3fa00fa1c1fe8701a9b87251a1.js integrity="sha256-I80MfYNyY7nq65buLZzPopadqj+gD6HB/ocBqbhyUaE=" crossorigin=anonymous></script></head><body><header><nav><ul><li><a class=text_secondary href=https://daxpy.xyz/>DAXPY</a></li><li>|</li><li><a class=text_secondary href=https://daxpy.xyz/posts/>posts</a></li><li><a class=text_secondary href=https://daxpy.xyz/notes/>notes</a></li><li><a class=text_secondary href=https://daxpy.xyz/links/>links</a></li><li><a class=text_secondary href=https://daxpy.xyz/stories/>stories</a></li><li><a class=text_secondary href=/about>about</a></li></ul></nav></header><main><section><article><h1 id=ranknet-and-lambdarank>RankNet and LambdaRank</h1><p>The ranking problem is about ordering a collection of documents according to their relevance to the given query.</p><p>Their are multiple approaches to the problem, but in pairwise approach, we simply care about predicting order of document pairs for the query. Given 2 documents $d_i$ and $d_j$ the true relative ordering is specified as
$$h_{ij} = \begin{cases}1& d_i>d_j\\0& d_i=d_j\\-1& d_i&lt;d_j\\\end{cases}$$</p><p>In terms of modelling, we assume there is a base model takes in features $x_i$ corresponds to document $d_i$ and predict a score depicting relevance to the given query. $$s_i = f(x_i)$$</p><p>A comparator model is feed these scores which predicts
$\mathop{\mathrm{\operatorname{P}}}(d_i>d_j)$.</p><p>The comparator model can be a binary classifier by setting
$$y_{ij} \mathop{\mathrm{\triangleq}}\frac{1+h_{ij}}{2}$$ as target variable. The a comparator is trained to predict 1 for verifying the order and 0 for negating it.</p><h2 id=ranknet>RankNet</h2><p>RankNet uses a logistic regression as comparator which is feed the difference of scores.
$$\hat{y}_{ij} = \mathop{\mathrm{\operatorname{P}}}(d_i>d_j) = \frac{1}{1+e^{-\alpha(s_i-s_j)}}$$
$\alpha$ is a parameter which controls the slope of sigmoid function.</p><p>We can define binary cross entropy loss on this model as</p><p>$$C_{ij} = -(y_{ij}\log \hat{y}_{ij}+(1-y_{ij})\log (1- \hat{y}_{ij}))$$</p><p>Now consider a mini-batch of document ${d_1,\ldots,d_n}$ corresponding to a particular query. The documents have some perfect ordering to answer the query which is specified by values of $h_{ij}$.</p><p>For gradient update, we are interested in computing the gradients generated by each documents.
$$\begin{aligned}
\frac{\partial C}{\partial w} &= \frac{1}{n} \sum_{i=1}^{n} \frac{\partial C_i}{\partial w}
\\
w&\gets w-\eta \frac{\partial C}{\partial w}
\end{aligned}$$</p><p>Now, if we assume the documents follow the order $d_b>d_i>d_a$, then the loss incurred by the $d_i$ can be written as</p><p>$$\begin{aligned}
C_i &= -\sum_{a: d_i>d_a}y_{ia}\log \hat{y}_{ia} - \sum_{b:d_b>d_i}(1-y_{ib})\log (1-\hat{y}_{ib})
\end{aligned}$$</p><p>Note that the ground truth labels $y_{ia}=1$ and $y_{ib}=0$. The gradient from $d_i$ can also be simplified as</p><p>$$\begin{aligned}
\frac{\partial C_i}{\partial w}&=\sum_{a}\frac{\partial C_i}{\partial s_a}\frac{\partial s_a}{\partial w}+ \sum_{b}\frac{\partial C_i}{\partial s_b}\frac{\partial s_b}{\partial w}
\end{aligned}$$</p><p>The ${\partial s_\square}/{\partial w}$ part of the gradient only depends on the score prediction network. For computing the gradient of the comparator, we have
$$\begin{aligned}
\frac{\partial C_i}{\partial s_a}&=-\frac{\partial \log \hat{y}_{ia}}{\partial s_a} = \frac{-\alpha}{1+e^{\alpha(s_i-s_a)}}=-\alpha(1-\hat{y}_{ia})
\\
\frac{\partial C_i}{\partial s_b}&=-\frac{\partial \log (1- \hat{y}_{ib})}{\partial s_b} = \frac{-\alpha}{1+e^{-\alpha(s_i-s_b)}}=-\alpha\hat{y}_{ib}
\end{aligned}$$</p><p>If we randomly select a document pair $(d_i,d_j)$, the gradients would
be</p><p>$$\begin{aligned}
\frac{\partial C_i}{\partial s_j} &=
\begin{cases} \alpha(\hat{y}_{ij}-1) &amp;d_i>d_j<del>or</del>h_{ij}=1
\\
-\alpha\hat{y}_{ij}&amp;d_j>d_i<del>or</del>h_{ij}=-1\end{cases}
\end{aligned}$$</p><p>Now if we define the quantities
$$\lambda_{ij} \mathop{\mathrm{\triangleq}}\alpha\left[\frac{(1-h_{ij})}{2}-(1-\hat{y}_{ij})\right]$$
we can write the individual gradient as $$\begin{aligned}
\frac{\partial C_i}{\partial w}&= \sum_a\lambda_{ia}\frac{\partial s_a}{\partial w} - \sum_b\lambda_{ib}\frac{\partial s_b}{\partial w}
\\
\frac{\partial C}{\partial w}&= \frac{1}{n}\sum_{i=1}^{n}\lambda_{i}\frac{\partial s_i}{\partial w}
\\
\lambda_i &= \sum_{d_i > d_j} \lambda_{ij} - \sum_{d_i &lt; d_j} \lambda_{ij}
\end{aligned}$$</p><p>So for each document in the batch, we can simply accumulate $\lambda$ and then apply it to the gradient thus not requiring $n^2$ gradient computation.</p><p>Each $\lambda_i$ can also be thought of as the strength of gradient, getting larger for every inversions in the the ordering and getting smaller for correct orderings.</p><h2 id=lambdarank>LambdaRank</h2><p>At this point explaining lambda rank is very simple. Its exactly same as RankNet, but we modify computation of $\lambda$&rsquo;s as follows.
$$\lambda_{ij} \mathop{\mathrm{\triangleq}}-\alpha(1-\hat{y}_{ij})|\Delta_{NDCG}|$$</p><p>$\Delta_{NDCG}$ is the change in $NDCG$ measure if we swap $d_i$ and $d_j$ in the ordering. This results in gradient updates optimising for NDCG measure. Since in terms of NDCG, higher is better, we have to do
gradient ascent instead of gradient descent
$$w \gets w + \eta \left(\frac{1}{n}\sum_{i=1}^{n}\lambda_{i}\frac{\partial s_i}{\partial w} \right)$$</p></article><br><br><br><i>tags:</i>
<a class=gray style=padding-right:5px href=/tags#ranking><i>#ranking</i></a>
<a class=gray style=padding-right:5px href=/tags#search><i>#search</i></a></section></main><footer><p>...</p></footer></body></html>