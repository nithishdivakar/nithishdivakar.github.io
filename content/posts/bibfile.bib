@article{Edward and Yelong (2022),
  title={LoRA: Low-rank adaptation of large language models.},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal={ICLR},
  volume={1},
  number={2},
  pages={3},
  year={2022},
  url={https://arxiv.org/abs/2106.09685}
}

@inproceedings{Shih and Chien (2014),
  title={DoRA: Weight-decomposed low-rank adaptation},
  author={Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
  url={https://arxiv.org/abs/2402.09353}
}

@article{Mallat and Zhang (1993),
  title={Matching pursuits with time-frequency dictionaries},
  author={Mallat, Stephane G and Zhang, Zhifeng},
  journal={IEEE Transactions on signal processing},
  volume={41},
  number={12},
  pages={3397--3415},
  year={1993},
  publisher={IEEE},
  url={http://www.iro.umontreal.ca/~pift6080/H09/documents/papers/sparse/mallat_zhang_matching_pursuit.pdf}
}

@article{Harman and Lacko (2010),
  title={On decompositional algorithms for uniform sampling from n-spheres and n-balls},
  author={Harman, Radoslav and Lacko, Vladim{\'\i}r},
  journal={Journal of Multivariate Analysis},
  volume={101},
  number={10},
  pages={2297--2304},
  year={2010},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/pii/S0047259X10001211}
}

@article{Voelker et al. (2017),
  title={Efficiently sampling vectors and coordinates from the n-sphere and n-ball},
  author={Voelker, Aaron R and Gosmann, Jan and Stewart, Terrence C},
  journal={Centre for Theoretical Neuroscience-Technical Report},
  volume={1},
  year={2017},
  url={https://compneuro.uwaterloo.ca/files/publications/voelker.2017.pdf}
}

@article{Friedman (2001),
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H.},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR},
  url={https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.pdf}
}

@inproceedings{Chen et al. (2016),
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016},
  url={https://arxiv.org/pdf/1603.02754.pdf}
}

@article{Santurkar et al. (2018),
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018},
  url={https://arxiv.org/pdf/1805.11604.pdf}
}

@online{Doe:2009:Online,
  author = {Doe, Ringo},
  title = {This is a test entry of type {@ONLINE}},
  month = jun,
  year = {2009},
  url = {http://www.test.org/doe/},
  note = "[accessed 19-July-2008]"
}

@article{Blei et al. (2017),
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis},
  url={https://arxiv.org/abs/1601.00670}
}
    
@article{Ho et al. (2020),
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020},
  url={https://arxiv.org/pdf/2006.11239.pdf}
}
    
@article{Ioffe et al. (2015),
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr},
  url={http://proceedings.mlr.press/v37/ioffe15.pdf},
}

@article{Kingma et al. (2013),
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013},
  url={https://arxiv.org/abs/1312.6114},
}
    
@article{Kingma et al. (2019),
  title={An introduction to variational autoencoders},
  author={Kingma, Diederik P and Welling, Max and others},
  journal={Foundations and Trends in Machine Learning},
  volume={12},
  number={4},
  pages={307--392},
  year={2019},
  publisher={Now Publishers, Inc.},
  url={https://arxiv.org/pdf/1906.02691.pdf},
}
    
@article{Lei Ba et al. (2016),
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}, 
  url={https://arxiv.org/abs/1607.06450},
}

@article{Luo et al. (2018),
  title={Differentiable learning-to-normalize via switchable normalization},
  author={Luo, Ping and Ren, Jiamin and Peng, Zhanglin and Zhang, Ruimao and Li, Jingyu},
  journal={arXiv preprint arXiv:1806.10779},
  year={2018},
  url={https://arxiv.org/abs/1806.10779},
}
    
@article{Miyato et al. (2018),
  title={Spectral normalization for generative adversarial networks},
  author={Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  journal={arXiv preprint arXiv:1802.05957},
  year={2018},
  url={https://arxiv.org/pdf/1802.05957.pdf},
}

@inproceedings{Ranganath et al. (2014),
  title={Black box variational inference},
  author={Ranganath, Rajesh and Gerrish, Sean and Blei, David},
  booktitle={Artificial intelligence and statistics},
  pages={814--822},
  year={2014},
  organization={PMLR},
  url={http://www.cs.columbia.edu/~blei/papers/RanganathGerrishBlei2014.pdf},
}

@inproceedings{Rezende et al. (2014),
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1278--1286},
  year={2014},
  organization={PMLR},
  url={https://arxiv.org/pdf/1401.4082.pdf}
}

@article{Ruiz et al. (2016),
  title={The generalized reparameterization gradient},
  author={Ruiz, Francisco R and AUEB, Titsias RC and Blei, David and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={http://www.cs.columbia.edu/~blei/papers/RuizTitsiasBlei2016b.pdf},
}
    
@article{Salimans et al. (2016),
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={https://arxiv.org/pdf/1602.07868.pdf},
}   

@inproceedings{Sohl-Dickstein et al. (2015),
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR},
  url={https://arxiv.org/pdf/1503.03585.pdf},
}
    
@article{Song et al. (2019),
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019},
  url={https://arxiv.org/abs/1907.05600},
}
    
@article{Song et al. (2023),
  title={Consistency models},
  author={Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2303.01469},
  year={2023},
  url={https://arxiv.org/abs/2303.01469},
}
    
@article{Ulyanov et al. (2016),
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016},
  url={https://arxiv.org/abs/1607.08022},
}
    
@article{Vincent et al. (2010),
  title={Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.},
  author={Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine and Bottou, L{\'e}on},
  journal={Journal of machine learning research},
  volume={11},
  number={12},
  year={2010},
  url={https://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf},
}
    
@inproceedings{Welling et al. (2011),
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
  pages={681--688},
  year={2011},
  url={https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf},
}
    
@inproceedings{Wu et al. (2018),
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018},
  url={https://arxiv.org/abs/1803.08494},
}    

@article{Yang et al. (2019),
  title={A mean field theory of batch normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S},
  journal={arXiv preprint arXiv:1902.08129},
  year={2019},
  url={https://arxiv.org/pdf/1902.08129},
}
    
@article{Zhang et al. (2019),
  title={Root mean square layer normalization},
  author={Zhang, Biao and Sennrich, Rico},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019},
  url={https://arxiv.org/pdf/1910.07467.pdf},
}

@online{Amortized Inference and Variational Auto Encoders,
  title={Amortized Inference and Variational Auto Encoders},
  url={https://erdogdu.github.io/csc412/notes/lec11-1.pdf},
  note="[accessed -]"
}

@online{Gradient Descent,
  title={Gradient Descent},
  url={https://en.wikipedia.org/wiki/Gradient_descent},
  note=""
}

@online{Divergence,
  title={Divergence},
  url={https://en.wikipedia.org/wiki/Divergence_(statistics)},
  note="[accessed -]"
}

@online{Linear Regression,
  title={Linear Regression},
  url={https://en.wikipedia.org/wiki/Linear_regression},
  note=""
}

@online{Decision Tree,
  title={Decision Tree},
  url={https://en.wikipedia.org/wiki/Decision_tree_learning},
  note=""
}

@online{Evidence Lower Bound,
  title={Evidence Lower Bound},
  url={https://en.wikipedia.org/wiki/Evidence_lower_bound},
  note="[accessed -]"
}

@online{KL Divergence,
  title={KL Divergence},
  url={https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence},
  note="[accessed -]"
}

@online{Lipschitz Continuity,
  title={Lipschitz Continuity},
  url={https://en.wikipedia.org/wiki/Lipschitz_continuity},
  note="[accessed - Oct 2023]"
}

@online{Markov kernel,
  title={Markov kernel},
  url={https://en.wikipedia.org/wiki/Markov_kernel},
  note="[accessed - Oct 2023]"
}

@online{Matrix Norm,
  title={Matrix Norm},
  url={https://en.wikipedia.org/wiki/Matrix_norm},
  note="[accessed - Oct 2023]"
}

@online{Volume of an n ball,
  title={Volume of an n ball},
  url={https://en.wikipedia.org/wiki/Volume_of_an_n-ball},
  note=""
}

@online{Marsaglia polar method,
  title={Marsaglia's polar method},
  url={https://en.wikipedia.org/wiki/Marsaglia_polar_method},
  note=""
}

@online{Taylor series,
  title={Taylor's Series},
  url={https://en.wikipedia.org/wiki/Taylor_series},
  note=""
}

@online{Stochastic Approximation,
  title={Stochastic Approximation},
  url={https://en.wikipedia.org/wiki/Stochastic_approximation},
  note="[accessed -]"
}

@online{The variational auto-encoder,
  title={The variational auto-encoder},
  url={https://ermongroup.github.io/cs228-notes/extras/vae},
  note="[accessed -]"
}

@online{Variational Inference with Normalizing Flows,
  title={Variational Inference with Normalizing Flows},
  url={https://www.depthfirstlearning.com/2021/VI-with-NFs},
  note="[accessed -]"
}

@online{Variational inference,
  title={Variational inference},
  url={https://ermongroup.github.io/cs228-notes/inference/variational},
  note="[accessed -]"
}

@online{Ari Seff Diffusion Models youtube,
  title = {What are Diffusion Models?},
  author={Ari Seff},
  url={https://www.youtube.com/watch?v=fbLgFrlTnGU},
  note="[video]"
}

@online{Variational Inference: Foundations and Innovations, 
  title={Variational Inference: Foundations and Innovations},
  author={David Blei},
  url={https://www.youtube.com/watch?v=Dv86zdWjJKQ},
  note="[video]"
}

