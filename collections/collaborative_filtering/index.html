<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><title>Collaborative Filtering | DAXPY</title><link rel=stylesheet href=/css/main.min.d700ad2998f190f21436ef39c94129166ea316da7e0014005c9c2ced3b288a04.css integrity="sha256-1wCtKZjxkPIUNu85yUEpFm6jFtp+ABQAXJws7TsoigQ=" crossorigin=anonymous><script src=/js/main.23cd0c7d837263b9eaeb96ee2d9ccfa2969daa3fa00fa1c1fe8701a9b87251a1.js integrity="sha256-I80MfYNyY7nq65buLZzPopadqj+gD6HB/ocBqbhyUaE=" crossorigin=anonymous></script></head><body><header><nav><ul><li><a class=text_secondary href=https://daxpy.xyz/>DAXPY</a></li><li>|</li><li><a href=https://daxpy.xyz/posts/>Posts</a></li><li><a href=https://daxpy.xyz/notes/>Notes</a></li><li><a href=https://daxpy.xyz/collections/>Collections</a></li><li><a href=https://daxpy.xyz/links/>Links</a></li><li><a href=https://daxpy.xyz/stories/>Stories</a></li><li><a href=/about>About</a></li></ul></nav></header><main><a name=top></a><div style=text-align:right;height:5px;margin-top:10px class=italic>this page
⟩ <a href=/collections/>collections</a>
⟩ <a href=/>home</a></div><h1>Collaborative Filtering</h1><p>Whenever we discuss about collaborative filtering, the following image is
implicitly made as a anchor point to talk about how
collaborative filtering discovers &lsquo;similar users&rsquo; and use that to
recommend unseen items.</p><p>Whenever collaborative filtering is talked about, the following illustration is
brought up and then &ldquo;finding users who behave similarly, then recommend items they liked but haven&rsquo;t seen yet&rdquo; is discussed.</p><pre tabindex=0><code>
          movie 1   movie 2                                 movie n    
        ┌─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐ 
 user 1 │         │    ✓    │         │    ✓    │         │    ✓    │ 
        ├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤ 
 user 2 │    ✓    │    ✓    │         │         │         │         │ 
        ├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤ 
        │    ✓    │         │         │    ✓    │    ✓    │    ✓    │ 
        ├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤ 
        │         │         │    ✓    │         │         │         │ 
        ├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤ 
        │    ✓    │    ✓    │         │    ✓    │    ✓    │    ✓    │ 
        ├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤ 
 user m │         │    ✓    │         │    ✓    │         │         │ 
        └─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘ 
        
</code></pre><center><small><b>Fig :</b> The mythical user item interaction matrix.</small></center><p>It’s a helpful mental model and historically accurate for early recommender systems.</p><p>However, that similar users picture is only a small part of how modern
recommendation models actually work. Real-world systems rarely operate
directly on this matrix, and the notion of similarity today is far more
nuanced than simple row-to-row comparison.</p><p>This 5 part series is walkthrough of how collaborative filtering is practiced today.
We will talk about how the row-to-row comparison idea evolves into one of the
corner stone component of modern day recommender systems.</p><p><strong>Part 1: Collaborative Filtering - The Foundations & Classic Flaws</strong></p><ul><li>Introduction - The P(click) Problem</li><li>The &ldquo;Naive&rdquo; Approach: Neighborhood-Based CF</li><li>The Classic Foundation: Matrix Factorization (MF)</li><li>The &ldquo;Zero&rdquo; Problem: Why Standard MF is Wrong for Clicks</li></ul><p><strong>Part 2: The &ldquo;Zero&rdquo; Problem - Solving for Implicit Data</strong></p><ul><li>Solution 1: Weighted Matrix Factorization (WMF / Implicit ALS)</li><li>Solution 2: Logistic Matrix Factorization (LMF) & The Practical Hurdle of Negative Sampling</li></ul><p><strong>Part 3: The Modern Solution: Scaling with Features & Neural Networks</strong></p><ul><li>The Scaling Wall: Limitations of Pure Collaborative Filtering</li><li>The Modern Solution: Feature-Based Neural Networks</li><li>The &ldquo;Magic&rdquo; Ingredient: How Features are Represented (Embeddings)</li></ul><p><strong>Part 4: Retrieval & Ranking - Modern Recommendation Architectures</strong></p><ul><li>&ldquo;Two-Stage&rdquo; (Retrieval & Ranking) paradigm.</li><li>Architectural Deep Dive 1: The Two-Tower Model (For Retrieval)</li><li>Architectural Deep Dive 2: The Cross-Tower (or Fused) Model (For Ranking)</li></ul><p><strong>Part 5: Evaluation and Pitfalls</strong></p><ul><li>How Do We Know It&rsquo;s Working? (Evaluation Metrics: Offline, Online, Biases)</li><li>Conclusion: The Journey and What&rsquo;s Next. Multi-Task Learning (MTL), Reinforcement Learning (Contextual Bandits)</li></ul><ul><li><a href=/collections/collaborative_filtering/01/>Collaborative Filtering Part 01 - The Foundations & Classic Flaws</a></li><li><span>[wip] Collaborative Filtering Part 2 - The "Zero" Problem - Solving for Implicit Data</span></li><li><span>[wip] Collaborative Filtering Part 3 - Scaling with Features & Neural Networks</span></li></ul></main><footer><p>Found something useful here? pass it on; or tell me about it!<nav><ul><li><a href="https://drive.google.com/drive/folders/18LU6PKnxy8rDrAXhpiPXV2yOYlO_I8cF?usp=sharing">Resume</a></li><li><a href=https://daxpy.xyz/collections/>Collections</a></li><li><a href=https://www.linkedin.com/in/ndivakar/>Linkedin</a></li></ul></nav><small><a href=#top>↑ Top of page</a></small></p></footer></body></html>