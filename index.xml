<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Index on DAXPY</title><link>https://daxpy.xyz/</link><description>Recent content in Index on DAXPY</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 20 Jun 2025 00:00:00 +0530</lastBuildDate><atom:link href="https://daxpy.xyz/index.xml" rel="self" type="application/rss+xml"/><item><title>The Tyranny of Structurelessness</title><link>https://daxpy.xyz/links/2025-06-20-tyrany-of-structurelessness/</link><pubDate>Fri, 20 Jun 2025 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2025-06-20-tyrany-of-structurelessness/</guid><description/></item><item><title>Chesterton’s Fence: A Lesson in Thinking</title><link>https://daxpy.xyz/links/2025-06-16-chestertons-fence/</link><pubDate>Mon, 16 Jun 2025 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2025-06-16-chestertons-fence/</guid><description>&lt;p>&amp;hellip; a fence or gate erected across a road. The more modern type of reformer goes gaily up to it and says, “I don’t see the use of this; let us clear it away.” To which the more intelligent type of reformer will do well to answer: “If you don’t see the use of it, I certainly won’t let you clear it away. Go away and think. Then, when you can come back and tell me that you do see the use of it, I may allow you to destroy it.”&lt;/p></description></item><item><title>How to get promoted</title><link>https://daxpy.xyz/links/2025-05-29-how-to-get-promoted/</link><pubDate>Thu, 29 May 2025 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2025-05-29-how-to-get-promoted/</guid><description/></item><item><title>Errors vs. Bugs and the End of Stupidity</title><link>https://daxpy.xyz/links/2025-04-12-errors-vs-bugs/</link><pubDate>Sat, 12 Apr 2025 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2025-04-12-errors-vs-bugs/</guid><description/></item><item><title>Leverage Points: Places to Intervene in a System</title><link>https://daxpy.xyz/links/2025-01-23-leverage-points/</link><pubDate>Thu, 23 Jan 2025 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2025-01-23-leverage-points/</guid><description>&lt;p>&lt;img src="https://www.sfu.ca/content/dam/sfu/complex-systems-frameworks/Unpacking/Places-to-Intervene-in-a-System-V5.jpg" alt="test2" title="Title">&lt;/p></description></item><item><title>XGBoost</title><link>https://daxpy.xyz/posts/xgboost/</link><pubDate>Sun, 28 Apr 2024 21:30:00 +0530</pubDate><guid>https://daxpy.xyz/posts/xgboost/</guid><description>&lt;h1 id="xgboost">XGBoost&lt;/h1>
&lt;p>&lt;strong>Extreme Gradient Boosting&lt;/strong> or XGBoost is a technique that has become quite useful for solving prediction problems. XGBoost is also quite interesting academically; for it combines quite few techniques together to give us one robust method. The technique is composed from gradient boosting, decision trees, matching pursuit and gradient descent in function space among others. In this post, we will explore and derive the inner workings of XGBoost.&lt;/p>
&lt;h2 id="the-regression-problem">The Regression Problem&lt;/h2>
&lt;p>We are given a set of samples from population $\{(y_i,x_i)\}_{i=1}^{N}$ which we call a dataset. $y$&amp;rsquo;s are scalars and $x$ are vectors.&lt;/p></description></item><item><title>Sampling in a Sphere</title><link>https://daxpy.xyz/posts/sampling-in-a-sphere/</link><pubDate>Sun, 17 Mar 2024 21:44:15 +0530</pubDate><guid>https://daxpy.xyz/posts/sampling-in-a-sphere/</guid><description>&lt;h1 id="sampling-in-a-sphere">Sampling in a Sphere&lt;/h1>
&lt;p>Understanding how to generate a uniform sample of points inside a sphere takes us through a few interesting topics. So let begin with the end in mind.&lt;/p>
&lt;p>The following algorithm generates a uniform sample of points inside sphere in n dimensions.&lt;/p>
&lt;p>$$u_1, \ldots, u_{n+2} \sim \mathcal{N}(0,1)$$
$$x_1, \ldots, x_n = \frac{(u_1,\ldots, u_n)}{\sqrt{u_1^2+\ldots+u_{n+2}^{2}}}$$&lt;/p>
&lt;p>There is a lot to unpack here.&lt;/p>
&lt;ul>
&lt;li>Why are we sampling from a normal distribution to get a uniform distribution?&lt;/li>
&lt;li>Why $n+2$ ?&lt;/li>
&lt;li>Why are we dropping 2 coordinates?&lt;/li>
&lt;/ul>
&lt;h2 id="what-is-inside-a-sphere">What is inside a Sphere?&lt;/h2>
&lt;p>A sphere is defined as a set of points which are equidistant from a point known as center. For this article, we mostly deal with unit spheres. A unit n-sphere with center at origin can be defined as&lt;/p></description></item><item><title>Normalisation Layers</title><link>https://daxpy.xyz/posts/normalisation/</link><pubDate>Tue, 24 Oct 2023 18:33:10 +0530</pubDate><guid>https://daxpy.xyz/posts/normalisation/</guid><description>&lt;h1 id="normalisation">Normalisation&lt;/h1>
&lt;p>Regulating the magnitude of activations inside a neural network is crucial for an effective training regime. We may get stuck in local minima or worse yet, the training may diverge otherwise. For this, we make use of normalisation.&lt;/p>
&lt;p>Normalisation comes in two flavours. Weight normalisation and Layer normalisation. We briefly touch on some fundamental techniques in both.&lt;/p>
&lt;h2 id="weight-normalisation">Weight normalisation&lt;/h2>
&lt;p>In weight normalisation, we focus on the magnitude of the parameters of the network; preventing them from uncontrollable growth or collapse. The basic technique appeared in &lt;a href="https://arxiv.org/pdf/1602.07868.pdf" title="Salimans, Tim and Kingma, Durk P &amp;quot;Weight normalization: A simple reparameterization to accelerate training of deep neural networks&amp;quot; In Advances in neural information processing systems 29, (2016)">Salimans et al. (2016)&lt;/a> which describes a simple scenario.&lt;/p></description></item><item><title>Knapsack</title><link>https://daxpy.xyz/notes/knapsack/</link><pubDate>Fri, 20 Oct 2023 05:52:32 +0530</pubDate><guid>https://daxpy.xyz/notes/knapsack/</guid><description>&lt;h1 id="knapsack">Knapsack&lt;/h1>
&lt;p>Knapsack problems are probably the first introduction to many on problems where you are trying to optimize a dimension while constrained by another. Let&amp;rsquo;s look at it in depth.&lt;/p>
&lt;p>You are given a metaphorical knapsack which atmost can carry $W$ weight items. You are also given $n$ items, each with its own weight $w_i$ and value $v_i$. We are asked to select a few items from this set so that the total weight is atmost $W$ while maximising the total value.&lt;/p></description></item><item><title>Gradient Through Concatenation</title><link>https://daxpy.xyz/notes/gradient-through-concatenation/</link><pubDate>Mon, 02 Oct 2023 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/gradient-through-concatenation/</guid><description>&lt;h1 id="gradient-through-concatenation">Gradient Through Concatenation&lt;/h1>
&lt;p>Concatenation of vectors is a common operation in Deep Learning Networks. How can we compute derivative of the
output in the computational graph?&lt;/p>
&lt;p>We can write the operation as&lt;/p>
&lt;p>$$z = x|y$$&lt;/p>
&lt;p>Where $|$ is concat operator. We are interested in computing ${\partial z}/{\partial x}$ and ${\partial z}/{\partial y}$&lt;/p>
&lt;p>Assuming $x\in \mathbb{R}^m$ and $x\in \mathbb{R}^n$. We can rewrite the concat operation as&lt;/p>
&lt;p>$$z = \begin{bmatrix}I_m &amp;amp; 0\end{bmatrix}x+\begin{bmatrix}0 &amp;amp; I_n\end{bmatrix}y$$&lt;/p></description></item><item><title>Productivity Principles</title><link>https://daxpy.xyz/stories/productivity-principles/</link><pubDate>Sun, 30 Apr 2023 00:00:00 +0000</pubDate><guid>https://daxpy.xyz/stories/productivity-principles/</guid><description>&lt;h1 id="productivity-principles">Productivity Principles&lt;/h1>
&lt;blockquote>
&lt;p>These are not correct, but these are mine, adopted and refined from somewhere. I begin by saying &amp;ldquo;&lt;strong>&lt;a href="https://dictionary.cambridge.org/dictionary/english/your-mileage-may-vary">Your milage may vary&lt;/a>, but&lt;/strong>&amp;rdquo;.&lt;/p>&lt;/blockquote>
&lt;h2 id="barely-working-systems">Barely working systems&lt;/h2>
&lt;p>I define system as a sequence of steps you do one after the other which allows you to accomplish a goal. It can be as simple as the order you walk in a grocery shop to the way you start your day. Overtime, systems become habits.
Here are some better examples&lt;/p></description></item><item><title>Variational Inference</title><link>https://daxpy.xyz/posts/variational-inference/</link><pubDate>Sun, 16 Apr 2023 12:15:00 +0530</pubDate><guid>https://daxpy.xyz/posts/variational-inference/</guid><description>&lt;h1 id="variational-inference">Variational Inference&lt;/h1>
&lt;p>We have some data from a population and we suspect that the it is generated by some underlying process. Estimating the process which generates the data allows us to understand its fundamental properties.&lt;/p>
&lt;p>Concretely, $p(x)$ is the distribution of the data and $z$ are its latent variables, the process which generates the data is $p(x|z)$.
Estimating the generation process is computing the true posterior $p(z|x)$. This is the (posterior) inference problem.&lt;/p></description></item><item><title>Blowing up - How Nassim Taleb turned the inevitability of disaster into an investment strategy</title><link>https://daxpy.xyz/links/2022-12-27-blowing-up/</link><pubDate>Tue, 27 Dec 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-12-27-blowing-up/</guid><description>&lt;p>How Nassim Taleb turned the inevitability of disaster
into an investment strategy.&lt;/p></description></item><item><title>We are all confident idiots</title><link>https://daxpy.xyz/links/2022-12-23-we-are-all-confident-idiots/</link><pubDate>Fri, 23 Dec 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-12-23-we-are-all-confident-idiots/</guid><description/></item><item><title>Why it breaks your brain to take a compliment</title><link>https://daxpy.xyz/links/2022-12-20-why-it-breaks-your-brain-to-take-a-compliment/</link><pubDate>Tue, 20 Dec 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-12-20-why-it-breaks-your-brain-to-take-a-compliment/</guid><description/></item><item><title>Diffusion Models</title><link>https://daxpy.xyz/links/2021-09-20-diffusion-models/</link><pubDate>Tue, 20 Sep 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2021-09-20-diffusion-models/</guid><description/></item><item><title>This is Water</title><link>https://daxpy.xyz/links/2022-04-23-this-is-water/</link><pubDate>Sat, 23 Apr 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-04-23-this-is-water/</guid><description>&lt;p>This article is about the value of a real education, which has almost nothing to do with knowledge, and everything to do with simple awareness; awareness of what is so real and essential, and hidden in plain sight all around us.&lt;/p></description></item><item><title>How to be perfectly unhappy</title><link>https://daxpy.xyz/links/2022-04-20-perfectly-unhappy/</link><pubDate>Wed, 20 Apr 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-04-20-perfectly-unhappy/</guid><description/></item><item><title>Gradient Boosting</title><link>https://daxpy.xyz/notes/gradient-boosting/</link><pubDate>Thu, 14 Apr 2022 04:00:00 +0530</pubDate><guid>https://daxpy.xyz/notes/gradient-boosting/</guid><description>&lt;h1 id="gradient-boosting">Gradient Boosting&lt;/h1>
&lt;p>The general framework of Boosting is learners are added in greedy manner to minimise loss.
$$F_t(x) = F_{t-1}(x) + f_t(x)$$
At the $t^{th}$ step, we are interested in learning the function $f$ which minimised the loss. The value of loss function at this point is given by&lt;/p>
&lt;p>$$\begin{aligned}
L &amp;amp;= l(y,p+f(x))
\\
&amp;amp;=l(y,p) + \nabla_{p} l(y,p)f(x)
\end{aligned}$$&lt;/p>
&lt;p>The last step is from first order taylor series approximation of $l$.
$$f(x) = f(a) + (x-a) f^{\prime}(a)$$&lt;/p></description></item><item><title>Attribute Selection in Decision Trees</title><link>https://daxpy.xyz/notes/attribute-selection-in-decision-trees/</link><pubDate>Thu, 14 Apr 2022 00:15:30 +0530</pubDate><guid>https://daxpy.xyz/notes/attribute-selection-in-decision-trees/</guid><description>&lt;h1 id="attribute-selection-in-decision-trees">Attribute Selection in Decision Trees&lt;/h1>
&lt;p>For constructing a new node in decision tree, choosing which attribute to partition the data on is important. Choosing a less desirable attribute to split the data on may result in lower performance. Lets look into a few important measures which helps us find the best attribute.&lt;/p>
&lt;h2 id="information-gain">Information Gain&lt;/h2>
&lt;p>Information Gain is defined as amount of information gained about a random variable (outcome) from observing another (attribute).
We can quantify information gain as difference in entropy when random variable is observed.&lt;/p></description></item><item><title>Common Knowledge and Aumann’s Agreement Theorem</title><link>https://daxpy.xyz/links/2022-04-03-common-knowledge/</link><pubDate>Sun, 03 Apr 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-04-03-common-knowledge/</guid><description>&lt;p>The mere act of saying something publicly can change the world—even if everything you said was already obvious to every last one of your listeners.&lt;/p></description></item><item><title>Reservoir Sampling</title><link>https://daxpy.xyz/notes/reservoir-sampling/</link><pubDate>Fri, 01 Apr 2022 04:00:00 +0530</pubDate><guid>https://daxpy.xyz/notes/reservoir-sampling/</guid><description>&lt;h1 id="reservoir-sampling">Reservoir Sampling&lt;/h1>
&lt;p>How can you uniformly sample $k$ items from a stream?&lt;/p>
&lt;p>Reservoir Sampling is used when you want a uniform sample from a stream. The length of the stream is not known before and the stream is large enough that we cannot look back or store everything.&lt;/p>
&lt;p>The algorithm is simple.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Reservoir Sampling&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>reservoir[&lt;span style="color:#ae81ff">1&lt;/span>:k] &lt;span style="color:#f92672">=&lt;/span> stream[&lt;span style="color:#ae81ff">1&lt;/span>:k]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i&lt;span style="color:#f92672">=&lt;/span>k&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> to n
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> j &lt;span style="color:#f92672">=&lt;/span> random(&lt;span style="color:#ae81ff">1&lt;/span>,i)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> j &lt;span style="color:#f92672">&amp;lt;&lt;/span> k:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reservoir[j] &lt;span style="color:#f92672">=&lt;/span> stream[i]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let prove the above process does infact gives us a uniform sample.&lt;/p></description></item><item><title>Quick Select</title><link>https://daxpy.xyz/notes/quick-select/</link><pubDate>Mon, 14 Mar 2022 08:30:00 +0530</pubDate><guid>https://daxpy.xyz/notes/quick-select/</guid><description>&lt;h1 id="quick-select">Quick Select&lt;/h1>
&lt;p>The core technique in quick sort is partition procedure. The partition procedure partitions the array into 2 segments such that for a choosen pivot element, one segment has all element smaller or equal and the other has all element larger than pivot.&lt;/p>
&lt;p>The procedure itself has applications beyond quick sort like selecting the smallest $k$ elements if sorted order is not required.&lt;/p>
&lt;p>There are 2 main techniques to implement quick select.&lt;/p></description></item><item><title>Canny Edge detector</title><link>https://daxpy.xyz/notes/canny-edge-detector/</link><pubDate>Sat, 12 Mar 2022 12:00:00 +0530</pubDate><guid>https://daxpy.xyz/notes/canny-edge-detector/</guid><description>&lt;h1 id="canny-edge-detector">Canny Edge detector&lt;/h1>
&lt;p>Steps:&lt;/p>
&lt;ul>
&lt;li>Apply &lt;strong>Gaussian filtering&lt;/strong> to smooth out noise in the image&lt;/li>
&lt;li>&lt;strong>Compute gradients&lt;/strong>: Compute horizontal($G_x$) and vertical gradients ($G_y$). Magnitude and direction of gradients can then be compluted as
$$\begin{aligned}
m &amp;amp;= \sqrt{G_x^2+G_y^2}
&amp;amp;
\theta &amp;amp;= \tan ^{-1}\left(\frac{G_y}{G_x}\right)
\end{aligned}$$
The angle is then rounded off so that $\theta \in {0,45,90,135}$&lt;/li>
&lt;li>&lt;strong>Non-maximal suppression&lt;/strong>: For each pixel $(m,\theta)$, if its gradient intensity is maximum among the pixels in negative and positive gradient direction, the value is preserved. Otherwise it is suppressed.&lt;/li>
&lt;li>&lt;strong>Double thresholding&lt;/strong>
$$\begin{aligned}
m \geq t_h &amp;amp;\implies \text{strong edge pixel}
\\
t_l &amp;lt; m &amp;lt; t_h &amp;amp;\implies \text{weak edge pixel}
\\
m \leq t_l &amp;amp;\implies \text{suppress}
\end{aligned}$$&lt;/li>
&lt;li>&lt;strong>Edge tracking by hysteresis&lt;/strong>: All strong pixels are selected as true edge pixels. All the weak pixels which has a strong pixel in its $8 \times 8$ neighbourhood are also selected as a true edge. All the others are removed.&lt;/li>
&lt;/ul></description></item><item><title>Histogram of Oriented Gradients</title><link>https://daxpy.xyz/notes/histogram-of-oriented-gradients/</link><pubDate>Sat, 12 Mar 2022 00:00:30 +0530</pubDate><guid>https://daxpy.xyz/notes/histogram-of-oriented-gradients/</guid><description>&lt;h1 id="histogram-of-oriented-gradients">Histogram of Oriented Gradients&lt;/h1>
&lt;p>Steps to compute HoG of an image.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Gradients computation:&lt;/strong> Compute image gradients $G_x$ and $G_y$ by convolving the image with $[−1,0,1]$ and $[−1,0,1]^{T}$ respectively&lt;/li>
&lt;li>&lt;strong>Magnitude and direction&lt;/strong> of each pixel
$$\begin{aligned}
m &amp;amp;= \sqrt{G_x^2+G_y^2}
&amp;amp;
\theta &amp;amp;= \tan^{-1}\left(\frac{G_y}{G_x}\right)
\end{aligned}$$&lt;/li>
&lt;li>For each cell in the image ($8 \times 16$)
&lt;ul>
&lt;li>&lt;strong>Oriented histogram&lt;/strong> The histogram is created by binning pixel orientation $\theta$&lt;/li>
&lt;li>For a consecutive bin pair $(\theta_l,\theta_r)$ where a pixel $(m,\theta)$ falls, the histogram is populated as
$$\begin{aligned}
V(\theta_l) &amp;amp;= \frac{(\theta-\theta_L)}{|bin|}m
&amp;amp;
V(\theta_r) &amp;amp;= \frac{(\theta_r-\theta)}{|bin|}m
\end{aligned}$$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Normalise histograms&lt;/strong>
Combine(concatenate) histograms of neighbouring $2 \times 2$ overlapping cells blocks and $\ell_2$ normalise this histogram. This step is to prevent lighting based variations in the image on the histogram&lt;/li>
&lt;/ul></description></item><item><title>KKT conditions and Lagrange multipliers</title><link>https://daxpy.xyz/notes/kkt-conditions/</link><pubDate>Fri, 11 Mar 2022 06:15:30 +0530</pubDate><guid>https://daxpy.xyz/notes/kkt-conditions/</guid><description>&lt;h1 id="karush-kuhn-tucker-conditions">Karush-Kuhn-Tucker conditions&lt;/h1>
&lt;p>A typical constrained optimisation problem is as follows.
$$\begin{aligned}
\min_{x\in\mathbb{R}^n}&amp;amp;f(x)
\\
s.t.~h_i(x) &amp;amp;= 0
\\
g_j(x) &amp;amp;\leq 0
\end{aligned}$$&lt;/p>
&lt;h2 id="karush-kuhn-tucker-conditions-1">Karush-Kuhn-Tucker conditions&lt;/h2>
&lt;p>If the negative of the gradient (of $f$) has any component along an equality constraint $h(x)=0$, then we can take small steps along this surface to reduce $f(x)$.&lt;/p>
&lt;p>Since $\nabla h(x)$, the gradient of the equality constraint is always perpendicular to the constraint surface $h(x)=0$, at optimum, $-\nabla f(x)$ should be either parallel or anti-parallel to $\nabla h(x)$
$$-\nabla f(x) = \mu \nabla h(x)$$
A similar argument can be made for inequality constraints. These form KKT conditions. So at an optimum point $x^\ast$ we have,
$$\begin{aligned}
h_i(x^\ast)&amp;amp;=0
&amp;amp;
g_j(x^\ast) &amp;amp;\leq 0
\\
\lambda_j g_j(x^\ast) &amp;amp;= 0
&amp;amp;
\lambda_j &amp;amp;\geq 0
\end{aligned}$$
$$\nabla f(x^\ast) +\sum_{i} \mu_i\nabla h(x^\ast) + \sum_j \lambda_j \nabla g_j(x^\ast)= 0$$
These are the KKT conditions for constrained optimisation.&lt;/p></description></item><item><title>BFGS</title><link>https://daxpy.xyz/notes/bfgs/</link><pubDate>Fri, 11 Mar 2022 00:15:30 +0530</pubDate><guid>https://daxpy.xyz/notes/bfgs/</guid><description>&lt;h1 id="bfgs">BFGS&lt;/h1>
&lt;h2 id="newtons-method">Newton&amp;rsquo;s Method&lt;/h2>
&lt;p>$$\begin{aligned}
x_{k+1} &amp;amp;= x_k - [H(x_k)]^{-1}\nabla f(x_k)^\intercal
\end{aligned}$$&lt;/p>
&lt;h2 id="quasi-newtons-method">Quasi Newton&amp;rsquo;s Method&lt;/h2>
&lt;p>$$\begin{aligned}
x_{k+1} &amp;amp;= x_k - \alpha_kS_k {\nabla f(x_k)}^{T}
\end{aligned}$$&lt;/p>
&lt;p>If $S_k$ is inverse of Hessian, then method is Newton&amp;rsquo;s iteration; if $S_k=I$, then it is steepest descent&lt;/p>
&lt;h2 id="bfgs-1">BFGS&lt;/h2>
&lt;p>BFGS is a quasi newtons method where we approximate inverse of Hessian by $B_k$. The search direction $p_k$ is determined by solving
$$B_kp_k = -\nabla f(x_k)$$
A line search is performed in this search direction to find next point $x_{k+1}$ by minimising $f(x_k+\gamma p_k)$. The approximation to hessian is then updated as
$$\begin{aligned}
B_{k+1} &amp;amp;= B_k + \alpha_k u_ku_k^\intercal + \beta_k v_kv_k^\intercal
\\
u_k &amp;amp;= \nabla f(x_{k+1})-\nabla f(x_k)
\\
\alpha_k &amp;amp;= \frac{1}{\alpha u_k^\intercal p_k}
\\
v_k &amp;amp;= B_kp_k
\\
\beta_k &amp;amp;= \frac{-1}{p_k^\intercal B_kp_k}
\end{aligned}$$&lt;/p></description></item><item><title>Bias and Variance</title><link>https://daxpy.xyz/notes/bias-and-variance/</link><pubDate>Thu, 10 Mar 2022 10:15:30 +0530</pubDate><guid>https://daxpy.xyz/notes/bias-and-variance/</guid><description>&lt;h1 id="bias-and-variance">Bias and Variance&lt;/h1>
&lt;p>A training set is only a subset of the population of data. Bias-variance trade-off talks about characteristics of predictions from the same algorithm if we use different subsets of the population as training set.&lt;/p>
&lt;p>&lt;strong>Bias&lt;/strong> is difference between true value and average predictions from model trained on different training set.&lt;/p>
&lt;p>&lt;strong>Variance&lt;/strong> is an estimate of how much the average prediction varies when we change the training set.&lt;/p></description></item><item><title>Finding Median</title><link>https://daxpy.xyz/posts/finding-median/</link><pubDate>Tue, 01 Mar 2022 06:59:51 +0530</pubDate><guid>https://daxpy.xyz/posts/finding-median/</guid><description>&lt;h1 id="finding-median">Finding Median&lt;/h1>
&lt;p>&lt;em>Here is my &lt;a href="https://www.dictionary.com/e/slang/eli5/">ELI5&lt;/a> definition of a median.&lt;/em>&lt;/p>
&lt;blockquote>
&lt;p>&amp;ldquo;Median is the middle number when numbers are sorted&amp;rdquo;.&lt;/p>&lt;/blockquote>
&lt;p>There is only a single middle number when the size list is odd. But if the size is even, there are 2 middle numbers. Then we take an average of those 2 numbers to be the median.&lt;/p>
&lt;p>Median is useful when your data doesn&amp;rsquo;t behave. Medians are part of &amp;ldquo;robust statistics&amp;rdquo; because they are not affected by outliers. Both $[1,2,100]$ and $[1,2,3]$ have 2 as their median while their means differ widely. You can see why medians are not affected by noise.&lt;/p></description></item><item><title>Logic Bulling</title><link>https://daxpy.xyz/stories/logic-bulling/</link><pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate><guid>https://daxpy.xyz/stories/logic-bulling/</guid><description>&lt;h1 id="logic-bulling">Logic Bulling&lt;/h1>
&lt;p>I&amp;rsquo;m listening to &lt;a href="https://fs.blog/knowledge-project-podcast/adam-grant2/">this&lt;/a> podcast where Adam Grant talks about being a Logic Bully.&lt;/p>
&lt;p>When a student approached him seeking advice about a hard life decision, he proceeds to give a very logical answer. But instead of convincing the student; the argument simply confuses the student more.&lt;/p>
&lt;blockquote>
&lt;p>Logical Bullying is when you overwhelm someone with rational arguments so much so that even though they don&amp;rsquo;t agree with you, they cant fight back.&lt;/p></description></item><item><title>Failure Theory</title><link>https://daxpy.xyz/links/2022-02-14-failure-theory/</link><pubDate>Mon, 14 Feb 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-02-14-failure-theory/</guid><description>&lt;p>..Effectively the chances of small failures has decreased slightly but the chances of catastrophic failures has gone way up [&amp;hellip;.] the more edifice you build to prevent minor failures the larger the capacity you create for catastrophic ones&lt;/p></description></item><item><title>Binary Search</title><link>https://daxpy.xyz/posts/binary-search-problems/</link><pubDate>Fri, 28 Jan 2022 06:59:51 +0530</pubDate><guid>https://daxpy.xyz/posts/binary-search-problems/</guid><description>&lt;h1 id="binary-search">Binary Search&lt;/h1>
&lt;p>Binary search is more than just a search algorithm for sorted arrays. It&amp;rsquo;s an algorithm which keeps showing up as optimal solutions in unlikely places. This note is a very limited exploration of what binary search can do.&lt;/p>
&lt;p>Let&amp;rsquo;s begin by talking about vanilla binary search.&lt;/p>
&lt;h2 id="binary-search-1">Binary Search&lt;/h2>
&lt;p>We are given a sorted array of numbers and a target. Binary search is the most optimal way of finding position of target in the array if present.&lt;/p></description></item><item><title>Crony Beliefs</title><link>https://daxpy.xyz/links/2022-01-13-crony-beliefs/</link><pubDate>Thu, 13 Jan 2022 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2022-01-13-crony-beliefs/</guid><description/></item><item><title>Newton's Method</title><link>https://daxpy.xyz/notes/2022-01-04-newtons-method/</link><pubDate>Tue, 04 Jan 2022 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/2022-01-04-newtons-method/</guid><description>&lt;h1 id="newtons-method">Newton&amp;rsquo;s Method&lt;/h1>
&lt;p>To derive newton&amp;rsquo;s method, we simply have to find the optimum point from second order Taylor series expansion of $f(x)$
$$\begin{aligned}
x_{k+1} &amp;amp;= x_k - [H(x_k)]^{-1}\nabla f(x_k)^\intercal
\end{aligned}$$
&lt;em>Derivation&lt;/em>: From a point $x_k$, we want to compute the best possible move $x_k+s$ to minimise $f$. Using taylor series expansion, we have
$$f(x_k+s) = f(x_k) + s\nabla f(x_k) + \frac{s^2}{2!} H(x_k) = g(s)$$&lt;/p>
&lt;p>$$\begin{aligned}
0 &amp;amp;= \nabla_s g(s) = \nabla f(x_k) + s H(x_k)
\\
s &amp;amp;= - H(x_k)^{-1} {\nabla f(x_k)}^\intercal
\end{aligned}$$&lt;/p></description></item><item><title>Common Optimisers</title><link>https://daxpy.xyz/notes/common-optimisers/</link><pubDate>Sun, 24 Oct 2021 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/common-optimisers/</guid><description>&lt;h1 id="common-optimisers">Common Optimisers&lt;/h1>
&lt;p>$E$ is the loss function and $w$ is the model parameters;&lt;/p>
&lt;h2 id="stochastic-gradient-descent">Stochastic Gradient Descent&lt;/h2>
&lt;p>$$\begin{aligned}
w_{t+1}&amp;amp;= w_t - \alpha \nabla E(w_t)\end{aligned}$$&lt;/p>
&lt;h2 id="sgd-with-momentum">SGD with Momentum&lt;/h2>
&lt;p>&lt;em>Use gradient to update velocity/direction of a particle instead of only updating its position&lt;/em>&lt;/p>
&lt;p>$$\begin{aligned}
m_{t+1} &amp;amp;= \eta m_t + \alpha \nabla E(w_t)
\\
w_{t+1}&amp;amp;= w_t - m_{t+1}
\end{aligned}$$
This results in equivalent single update as
$$w_{t+1}= w_t - \alpha \nabla E(w_t) - \eta m_{t}$$&lt;/p></description></item><item><title>Focal Loss</title><link>https://daxpy.xyz/notes/2021-10-10-focal-loss/</link><pubDate>Sun, 10 Oct 2021 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/2021-10-10-focal-loss/</guid><description>&lt;h1 id="focal-loss">Focal Loss&lt;/h1>
&lt;p>For binary classification problem, the standard cross entropy loss is given by&lt;/p>
&lt;p>$$CE(p,y_t)=\begin{cases}-\log(p)&amp;amp;y_t=1
\\
-\log(1-p)&amp;amp;else\end{cases}$$&lt;/p>
&lt;p>We can simplify this to $CE(p_t) = -\log(p_t)$ if we define
$$p_t \mathop{\mathrm{\triangleq}}
\begin{cases}p&amp;amp;y_t=1
\\
1-p&amp;amp;else\end{cases}$$&lt;/p>
&lt;p>What if there is a huge imbalance between no of positive and negative samples? The standard way of fixing this would be to add a balancing term $\alpha$ which is derived from inverse class frequencies. Let&lt;/p>
&lt;p>$$\alpha_t \mathop{\mathrm{\triangleq}}\begin{cases}\alpha&amp;amp;y_t=1\\1-\alpha&amp;amp;else\end{cases}$$&lt;/p></description></item><item><title>The Gervais Principle, Or The Office According to “The Office”</title><link>https://daxpy.xyz/links/2021-10-03-the-gervais-principle/</link><pubDate>Sun, 03 Oct 2021 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2021-10-03-the-gervais-principle/</guid><description/></item><item><title>RankNet and LambdaRank</title><link>https://daxpy.xyz/notes/2021-09-25-ranknet-and-lambdarank/</link><pubDate>Sat, 25 Sep 2021 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/2021-09-25-ranknet-and-lambdarank/</guid><description>&lt;h1 id="ranknet-and-lambdarank">RankNet and LambdaRank&lt;/h1>
&lt;p>The ranking problem is about ordering a collection of documents according to their relevance to the given query.&lt;/p>
&lt;p>Their are multiple approaches to the problem, but in pairwise approach, we simply care about predicting order of document pairs for the query. Given 2 documents $d_i$ and $d_j$ the true relative ordering is specified as
$$h_{ij} = \begin{cases}1&amp;amp; d_i&amp;gt;d_j\\0&amp;amp; d_i=d_j\\-1&amp;amp; d_i&amp;lt;d_j\\\end{cases}$$&lt;/p>
&lt;p>In terms of modelling, we assume there is a base model takes in features $x_i$ corresponds to document $d_i$ and predict a score depicting relevance to the given query. $$s_i = f(x_i)$$&lt;/p></description></item><item><title>The Bus Ticket Theory of Genius</title><link>https://daxpy.xyz/links/2021-09-23-the-bus-ticket-theory-of-genius/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2021-09-23-the-bus-ticket-theory-of-genius/</guid><description>&lt;p>&amp;ldquo;If I had to put the recipe for genius into one sentence, that might be it: to have a disinterested obsession with something that matters&amp;rdquo;&lt;/p></description></item><item><title>Evolution of Search Engines</title><link>https://daxpy.xyz/links/2021-09-21-evolution-of-seach-engines/</link><pubDate>Tue, 21 Sep 2021 00:00:00 +0530</pubDate><guid>https://daxpy.xyz/links/2021-09-21-evolution-of-seach-engines/</guid><description/></item><item><title>Movie Reviews and Gradient Descent</title><link>https://daxpy.xyz/notes/2021-04-13-014-movie-reviews-and-gradient-descent/</link><pubDate>Tue, 13 Apr 2021 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/2021-04-13-014-movie-reviews-and-gradient-descent/</guid><description>&lt;h1 id="movie-reviews-and-gradient-descent">Movie Reviews and Gradient Descent&lt;/h1>
&lt;p>The problem is simple; $m$ movies, $n$ users and we have the data of rating of movies by users. Now in reality, each user might have rated a few movies while total number of users and movies are huge. We can consider the whole ratings data as a matrix $n\times m$ matrix $R$ where $R_{ij}$ is the rating of $i^{th}$ movie by $j^{th}$ user.&lt;/p>
&lt;p>We want a model which can predict the rating a user would have given a movie. Now the modelling part is easy as a matrix factorisation problem. We can assume every user is represented by a embedding $u_i$ and similarly, every movie has a embedding $m_j$. We simply want $$R_{ij} \sim { u_i}^\intercal m_j$$ If we simply model the learning problem as
$$\mathop{\mathrm{arg,min}}_{U,M} \| {U}^\intercal M - R \|_2$$
then we are implicitly assuming that all unavailable ratings are $0$. Since we have only a few ratings compared to all possible combinations of movies and users, the model will get biased towards $0$ ratings.&lt;/p></description></item><item><title>Softmax Classifier</title><link>https://daxpy.xyz/notes/softmax_classifier/</link><pubDate>Mon, 13 Jan 2020 00:00:51 +0530</pubDate><guid>https://daxpy.xyz/notes/softmax_classifier/</guid><description>&lt;h1 id="softmax-classifier">Softmax Classifier&lt;/h1>
&lt;p>Imagine we have a dataset $\{x,y\}_{i=0}^m$ where $x$ is a data point
and $y$ indicates the class $x$ belongs to. For deriving LDA classifier,
we had modeled the class conditional density $P(x|y)$ as a Gaussian and
derived the posterior probabilities $P(y|x)$. Here, we will directly
model the posterior with a linear function. Since the posterior directly
models what class a data point belongs to, we don&amp;rsquo;t have much to do
after to get a classifier.&lt;/p></description></item><item><title>Gradient Through Addition with Broadcasting</title><link>https://daxpy.xyz/notes/2018-09-18-gradient-through-addition-with-bradcasting/</link><pubDate>Tue, 18 Sep 2018 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/2018-09-18-gradient-through-addition-with-bradcasting/</guid><description>&lt;h1 id="gradient-through-addition-with-broadcasting">Gradient Through Addition with Broadcasting&lt;/h1>
&lt;p>Calculating gradient across an addition is a simple
algebra trick. But this gets complicated when we look at addition of tensors which allows
broadcasting. In this post, we examine how to compute gradients in such situations.&lt;/p>
&lt;h2 id="gradient-of-addition">Gradient of Addition&lt;/h2>
&lt;p>Consider a simple sequence of operations. $A$ and $B$ are inputs which
ultimately leads to computation of a scalar loss/error term $l$.&lt;/p>
&lt;p>$$ z = A+B $$
$$ l \twoheadleftarrow z $$&lt;/p></description></item><item><title>Differentiable Computations</title><link>https://daxpy.xyz/posts/differentiable-computations/</link><pubDate>Sun, 18 Feb 2018 00:00:00 +0000</pubDate><guid>https://daxpy.xyz/posts/differentiable-computations/</guid><description>&lt;h1 id="differentiable-computations">Differentiable Computations&lt;/h1>
&lt;p>Auto-grad or automatic gradient computation is a nice feature found in many computational frameworks. Specify the computation in forward direction and the framework computes backward gradients. Let&amp;rsquo;s talk about the generic method to do this.&lt;/p>
&lt;p>Let&amp;rsquo;s say we have to compute the result of &amp;lsquo;something&amp;rsquo;. It may be a
nasty heat equation or some logic driven steps to get from input to
output. Abstracting the steps involved gives us a sequence of equations
$$\begin{aligned}
z_i = f_i(z_{a(i)})\end{aligned}$$&lt;/p></description></item><item><title>Linear Classifiers</title><link>https://daxpy.xyz/notes/linear_classifiers/</link><pubDate>Sun, 18 Feb 2018 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/linear_classifiers/</guid><description>&lt;h1 id="linear-classifiers">Linear Classifiers&lt;/h1>
&lt;p>In the post on bayes error, we discussed what is the best classifier if
the features are not enough to tell the class apart. We also derived
that in such situation, the best classifier is
$$h(x) = sign \left( n(x) - \frac{1}{2} \right)$$&lt;/p>
&lt;p>This formulation cannot be used in general situations as there is no easy way
to estimate $n(x) = P(y=+1|x)$ for a general distribution. But what if
$x$ has a simple distribution?&lt;/p></description></item><item><title>Bayes Error</title><link>https://daxpy.xyz/notes/bayes_error/</link><pubDate>Sun, 11 Feb 2018 05:04:51 +0530</pubDate><guid>https://daxpy.xyz/notes/bayes_error/</guid><description>&lt;h1 id="bayes-error">Bayes Error&lt;/h1>
&lt;p>In an ideal world, everything has reason. Every question has a unambiguous answer. The data in sufficient to explain its behaviours, like the class it belongs to.&lt;/p>
&lt;p>$$\begin{aligned}
g(x) = y \end{aligned}$$&lt;/p>
&lt;p>In the non ideal world, however, there is always something missing that stops us from knowing the entire truth. $g$ is beyond reach. In such cases we resort to probability.&lt;/p>
&lt;p>$$\begin{aligned}
n(x) = P(y=1|x)\end{aligned}$$&lt;/p>
&lt;p>It simply tells us how probable is the data belonging to a class($y=1$) if my observations are $x$.&lt;/p></description></item><item><title>About</title><link>https://daxpy.xyz/about/</link><pubDate>Sun, 13 Oct 1991 00:00:00 +0000</pubDate><guid>https://daxpy.xyz/about/</guid><description>&lt;h1 id="welcome-to-daxpy">Welcome to DAXPY&lt;/h1>
&lt;p>This space is inspired by the iconic DAXPY subroutine from the LINPACK package, a cornerstone of high-performance numerical computing.&lt;/p>
&lt;p>&lt;strong>DAXPY&lt;/strong>, which stands for &amp;ldquo;Double-precision A*X Plus Y,&amp;rdquo;&amp;quot; represents a fundamental operation in linear algebra. It performs the calculation , $Y \gets A \cdot X + Y$ where $A$ is a scalar (a single number), and $X$ and $Y$ are vectors (arrays of numbers). This elegant operation serves as a building block for more complex mathematical computations, such as matrix multiplication and solving large systems of equations.&lt;/p></description></item></channel></rss>