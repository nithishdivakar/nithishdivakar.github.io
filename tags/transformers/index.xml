<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Transformers on DAXPY</title><link>https://daxpy.xyz/tags/transformers/</link><description>Recent content in Transformers on DAXPY</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 01 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://daxpy.xyz/tags/transformers/index.xml" rel="self" type="application/rss+xml"/><item><title>Implementing Self Attention</title><link>https://daxpy.xyz/collections/ml_notes/03a/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://daxpy.xyz/collections/ml_notes/03a/</guid><description>&lt;h2 id="implementing-self-attention"&gt;Implementing Self Attention&lt;/h2&gt;
&lt;p&gt;b is batch, t is tokens and d is token embedding size.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;scaled_dot_attention&lt;/span&gt;(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Q: Tensor[b, t, d],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; K: Tensor[b, t, d],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; V: Tensor[b, t, d]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;) &lt;span style="color:#f92672"&gt;-&amp;gt;&lt;/span&gt; Tensor[b, t, d]:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; dot: Tensor[b, t, t] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; torch&lt;span style="color:#f92672"&gt;.&lt;/span&gt;einsum(&lt;span style="color:#e6db74"&gt;&amp;#39;b i d , b j d -&amp;gt; b i j&amp;#39;&lt;/span&gt;, Q, K) &lt;span style="color:#f92672"&gt;*&lt;/span&gt; sqrt(d)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; attention: Tensor[b, t, t] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; torch&lt;span style="color:#f92672"&gt;.&lt;/span&gt;softmax(dot, dim&lt;span style="color:#f92672"&gt;=-&lt;/span&gt;&lt;span style="color:#ae81ff"&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; out: Tensor[b, t, d] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; torch&lt;span style="color:#f92672"&gt;.&lt;/span&gt;einsum(&lt;span style="color:#e6db74"&gt;&amp;#39;t i j , t j d -&amp;gt; t i d&amp;#39;&lt;/span&gt;, attention, V)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;return&lt;/span&gt; out
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;self_attention&lt;/span&gt;(X: Tensor[b, t, c]) &lt;span style="color:#f92672"&gt;-&amp;gt;&lt;/span&gt; Tensor[b, t, d]:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Wq, Wk, Wv &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#f92672"&gt;...&lt;/span&gt; &lt;span style="color:#75715e"&gt;# define weight matrices&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Q: Tensor[b, t, d] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; torch&lt;span style="color:#f92672"&gt;.&lt;/span&gt;einsum(&lt;span style="color:#e6db74"&gt;&amp;#39;b i c, c d -&amp;gt; b i d&amp;#39;&lt;/span&gt;, X, Wq)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; K: Tensor[b, t, d] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; torch&lt;span style="color:#f92672"&gt;.&lt;/span&gt;einsum(&lt;span style="color:#e6db74"&gt;&amp;#39;b i c, c d -&amp;gt; b i d&amp;#39;&lt;/span&gt;, X, Wk)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; V: Tensor[b, t, d] &lt;span style="color:#f92672"&gt;=&lt;/span&gt; torch&lt;span style="color:#f92672"&gt;.&lt;/span&gt;einsum(&lt;span style="color:#e6db74"&gt;&amp;#39;b i c, c d -&amp;gt; b i d&amp;#39;&lt;/span&gt;, X, Wv)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;return&lt;/span&gt; scaled_dot_attention(Q, K, V)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description></item></channel></rss>